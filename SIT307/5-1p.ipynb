{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as linMod\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from “sampleData.csv”.  Create training and test datasets using random splitting (70-30)%. Print the train and test data. Create a linear regression model and report the model performance. (The last feature is the target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error for random split is 0.12829755581059538\n"
     ]
    }
   ],
   "source": [
    "def splitFeature(data, splitter):\n",
    "    y = data[splitter]\n",
    "    x = data.drop(columns=splitter)\n",
    "    return y, x\n",
    "\n",
    "data = pd.read_csv('sample_dataset.csv', header=0)\n",
    "dataFrame = pd.DataFrame(data)\n",
    "training = dataFrame.sample(frac = 0.7)\n",
    "test = dataFrame.drop(training.index)\n",
    "\n",
    "\n",
    "yTrain, xTrain = splitFeature(training, 'feature_31')\n",
    "\n",
    "yTest, xTest = splitFeature(test, 'feature_31')\n",
    "\n",
    "linReg = linMod.LinearRegression()\n",
    "linReg.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = linReg.predict(xTest)\n",
    "\n",
    "print('mean squared error for random split is '+str(metrics.mean_squared_error(yTest.values, yPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test dataset using leave-one-out based on Subject ID. Print the train and test dataset for the first iteration only.  Create a linear regression model and compare the performance with Q-1. Explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  4.  4.  4.\n",
      "  4.  4.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  8.\n",
      "  8.  8.  8.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 11. 11. 11. 11.\n",
      " 11. 12. 12. 12. 12. 12. 13. 13. 13. 13. 13. 14. 14. 14. 14. 14. 15. 15.\n",
      " 15. 15. 15. 16. 16. 16. 16. 16. 17. 17. 17. 17. 17. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 20. 20. 20. 20. 20. 21. 21. 21. 21. 21. 22. 22. 22.\n",
      " 22. 22. 23. 23. 23. 23. 23. 24. 24. 24. 24. 24. 25. 25. 25. 25. 25. 26.\n",
      " 26. 26. 26. 26. 27. 27. 27. 27. 27. 28. 28. 28. 28. 28. 29. 29. 29. 29.\n",
      " 29. 30. 30. 30. 30. 30.]\n",
      "[1.         1.         0.04959209 0.54580452 0.77107666 0.38717123\n",
      " 0.61828996 0.86913206 0.13929588 0.45437667 0.39954379 0.45143146\n",
      " 0.75647282 0.1304868  0.60017831 0.50391657 0.69607497 0.7002525\n",
      " 0.27203852 0.55611664 0.21322323 0.41615536 0.67587356 0.27944222\n",
      " 0.1187282  0.97164694 0.51770336 0.39037537 0.36442293 0.94826759\n",
      " 0.92159212 0.98626525 0.98380373]\n",
      "0.24005368346857153\n",
      "[0.24005368346857153]\n",
      "mean squared error for leave-one-out is 0.24005368346857153\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('sample_dataset.csv', header=0)\n",
    "dataFrame = pd.DataFrame(data)\n",
    "\n",
    "x = data.iloc[:, 0:33].to_numpy()\n",
    "y = data.loc[:, 'feature_31'].to_numpy()\n",
    "\n",
    "print(x.T[0])\n",
    "print(x[range(len(x))][0])\n",
    "\n",
    "#loo = LeaveOneOut()\n",
    "#loo.get_n_splits(x)\n",
    "\n",
    "loo = LeaveOneGroupOut()\n",
    "loo.get_n_splits(x, y, x.T[0])\n",
    "\n",
    "errors = []\n",
    "for trainIndex, testIndex in loo.split(x, y, x.T[0]):\n",
    "    \n",
    "    xTrain, xTest = x[trainIndex], x[testIndex]\n",
    "    yTrain, yTrue = y[trainIndex], y[testIndex]\n",
    "    \n",
    "linReg = linMod.LinearRegression()\n",
    "linReg.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = linReg.predict(xTest)\n",
    "errors.append(metrics.mean_squared_error(yTrue, yPred))\n",
    "print(errors)\n",
    "\n",
    "print('mean squared error for leave-one-out is '+str(np.mean(errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the mean square error for leave-one-out is significantly higher than random sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
